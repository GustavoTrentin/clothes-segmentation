{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis distace and Amplify Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import cv2\n",
    "import tqdm\n",
    "    \n",
    "def mahal(img, select = None, mean_pix = None):\n",
    "    \"\"\" Improved Mahalanobis distance algorithm originally written \n",
    "        by Brandon Doyle.  This is written with care taken to NOT \n",
    "        use Python loops.  The key breakthrough here is numpy.einsum().\n",
    "        The original attempts to make this concise and fast resulted in really\n",
    "        weird explosions in RAM usage by NumPy.  The only way to make it settle\n",
    "        was to loop through each pixel value and apply transformations one at a\n",
    "        time.\n",
    "        \n",
    "        numpy.einsum is basically black magic until you understand it but once\n",
    "        you do you can make very efficient 1-step operations out of previously\n",
    "        slow multi-step ones.\n",
    "        \n",
    "        Args:\n",
    "        img:     Input image to compute mahalanobis distance on.\n",
    "        select:  Number of pixels to randomly select when computing the\n",
    "                 covariance matrix OR a specified list of indices in the \n",
    "                 image.  Specifying the indices outright would be faster\n",
    "                 if you have a bunch of images that are the same size.  \n",
    "                 The indices could be reused each time rather than recalculating\n",
    "                 every time you call the function.\n",
    "                 \n",
    "                 If select is 'None', then the every pixel in the image is \n",
    "                 included in the sample.\n",
    "        \"\"\"\n",
    "    # Flatten image to just one long array of RGB-valued pixels\n",
    "    arr = np.reshape(img, (img.shape[0] * img.shape[1], 3))\n",
    "\n",
    "    # no sampling.  use the entire image\n",
    "    if select is None:\n",
    "        select = arr\n",
    "    else:\n",
    "        # if 'select' is a number, generate an array of size 'select' containing\n",
    "        # random pixels in 'arr'.\n",
    "        # otherwise it should be a list of indices of pixels to choose.\n",
    "        select = arr[np.random.randint(0, arr.shape[0], select), :] if isinstance(select,int) else arr[select]\n",
    "            \n",
    "    # calculate the covariance matrix inverse using the sampled array\n",
    "    invcovar = inv(np.cov(np.transpose(select)))\n",
    "\n",
    "    if mean_pix is None:\n",
    "        # no provided mean RGB vector. Assume we are using the images own \n",
    "        # mean RGB value\n",
    "        meandiff = arr - np.mean(select, axis = 0)\n",
    "    else:\n",
    "        meandiff = arr - mean_pix\n",
    "    \n",
    "    # calculate the difference between every pixel in 'arr' and the mean RGB vector.\n",
    "    # if provided, use the given mean RGB vector, otherwise calculate the mean RGB \n",
    "    # value of 'select'\n",
    "    meandiff = arr - (mean_pix if mean_pix is not None else np.mean(select, axis = 0))\n",
    "\n",
    "    '''\n",
    "        Formula:\n",
    "            pp = particular pixel\n",
    "            mp = mean pixel value\n",
    "            MD = sqrt( transpose(pp - mp) * (covariance_mat^-1) * (pp - mp) )\n",
    "        \n",
    "        You'll notice that I've reversed which side gets transposed.  It's just because the\n",
    "        pixels are stored as rows at this point (above assumes column vectors) and I've set up\n",
    "        numpy.einsum() to handle the multiplication properly.\n",
    "    '''\n",
    "    \n",
    "    # calculate the first multiplication. \n",
    "    output = np.dot(meandiff, invcovar)\n",
    "\n",
    "    \n",
    "    # do literally everything else all in this step, then reshape back to image dimensions and return\n",
    "    return np.sqrt(np.einsum('ij,ij->i', output, meandiff)).reshape(img.shape[:-1])\n",
    "\n",
    "def amplify(image, mask, cutoff = 0):\n",
    "    \"\"\" Applies 'mask' to 'image' while cutting off values below a percent\n",
    "        brightness specified in cuttoff.\n",
    "        \n",
    "        Args:\n",
    "        image:   RGB/BGR image to amplify/apply mask to.\n",
    "        mask:    Grayscale/monocolor (one number per pixel) \"image\" to act as a mask.\n",
    "        cuttoff: Percent brightness below which pixels should be cut off.  This is \n",
    "                 referring to the brightness of pixels in 'mask' and the 100% setpoint \n",
    "                 is the brighted pixel in 'mask'.\n",
    "        \n",
    "        Returns the 'amplified' image.\"\"\"\n",
    "    \n",
    "    # cut off values below specified threshold\n",
    "    mask_modf = np.greater(mask*100.0/np.amax(mask), cutoff) * mask\n",
    "    \n",
    "    # apply mask\n",
    "    output = np.einsum('ij,ijk->ijk',mask_modf, image)/np.amax(mask_modf)\n",
    "    \n",
    "    # scale to 255 (2^8 - 1 = unsigned 8-bit max)\n",
    "    output *= (255.0/np.amax(image))\n",
    "    \n",
    "    return np.uint8(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94bfd56fe8e9495c8fd63ea721d901aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image', options=('CBOTA14STP0001_3.jpg', 'CLC0GAZLJNS1_C.jpg', 'CLâ€¦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import os\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "    \n",
    "images = os.listdir('images')\n",
    "\n",
    "def mahalanobis_segmentation(image):\n",
    "    pixelcounts = []\n",
    "    times = []\n",
    "\n",
    "    # read image\n",
    "    img = cv2.imread('images/' + image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # stuff for plots\n",
    "    pixelcounts.append(img.shape[0] * img.shape[1])\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "\n",
    "    # do mahalanobis distance calculation\n",
    "    t = time()\n",
    "    filt = mahal(img, None, mean_pix=[202,178,114])\n",
    "    times.append(time() - t)\n",
    "        \n",
    "    # put images in the 'plot buffer' if you will\n",
    "    ax1.imshow(img, interpolation = 'nearest')\n",
    "    ax2.imshow(filt, interpolation = 'nearest', cmap = 'Greys_r')\n",
    "    ax3.imshow(amplify(img, filt, cutoff = 255), interpolation = 'nearest' )\n",
    "    ax4.imshow(amplify(img, filt, cutoff = 25), interpolation = 'nearest')\n",
    "        \n",
    "    plt.show()   \n",
    "\n",
    "\n",
    "interactive(mahalanobis_segmentation, image = images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "20",
    "lenVar": "60"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6eab1c2c1466766817668c0ba9b34a6fb5cc6a68e28772209a3d685f8409d825"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
